- name: Add the user 'hadoop'
  user:
    name: hadoop
    groups: adm
    shell: /bin/bash
    create_home: true
  tags: ADD

- name: Assign password hadoop user
  shell: echo "hadoop:hadoop" | sudo chpasswd
  become: true
  tags: passwd

- name: Update repositories
  apt:
    update_cache: yes
  become: true

- name: Install dependencies
  apt:
    name: "{{ item }}"
    state: present
  with_items:
    - openjdk-8-jdk-headless
    - sshpass
  become: true

- name: Installing java
  apt_repository: repo='ppa:openjdk-r/ppa'

- name: Set JAVA_HOME
  lineinfile: dest=/etc/environment state=present regexp='^JAVA_HOME' line='JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64'

- name: download hadoop
  get_url:
    url: http://www-us.apache.org/dist/hadoop/common/hadoop-2.8.4/hadoop-2.8.4.tar.gz
    dest: /home/hadoop
    mode: 0777 
    owner: hadoop
    group: hadoop
  become: true
  
- name: Extract hadoop installer
  unarchive:
    src: /home/hadoop/hadoop-2.8.4.tar.gz
    dest: /home/hadoop
    remote_src: true 
    owner: hadoop
    group: hadoop
    mode: 0777
  become: true

- name: copying files to master
  copy:
    src: "{{ item }}"
    dest: /home/hadoop/hadoop-2.8.4/etc/hadoop/
    owner: hadoop
    group: hadoop
    mode: 0777
  become: true
  with_items:
    - core-site.xml
    - hdfs-site.xml

- name: Creates folders in masters
  file:
    path: /home/hadoop/{{ item }}
    state: directory
    mode: 0764
    owner: hadoop
    group: hadoop
    recurse: yes
  with_items:
    - ["tmp","name"]
  become: true

- name: Clean JAVA_HOME 
  shell: sed -i '/export JAVA_HOME=${JAVA_HOME}/d' ./hadoop-env.sh
  args:
    chdir:  /home/hadoop/hadoop-2.8.4/etc/hadoop
  become: true
  become_user: hadoop

- name: Add JAVA_HOME
  lineinfile:
      path: /home/hadoop/hadoop-2.8.4/etc/hadoop/hadoop-env.sh
      insertafter: '# The java implementation to use.'
      line: 'export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64'
  become_user: hadoop

- name: Move Home Hadoop
  command: mv /home/hadoop/hadoop-2.8.4 /usr/local/hadoop
  become: true
    

- name: Modified /etc/hosts
  lineinfile: 
    path: /etc/hosts
    insertafter: '127.0.0.1 localhost'
    state: present
    line: '127.0.0.1 hadoop-master'

- name: Format HDFS
  shell: yes | ./hdfs namenode -format
  args:
    chdir: /usr/local/hadoop/bin
  become: true

- name: Delete path /usr/local/hadoop into /etc/enviroment
  command: sed -e 's|/usr/local/hadoop:||g' -i /etc/environment 
  become: true

- name: Append path /usr/local/hadoop into /etc/enviroment
  command: sed -e 's|PATH="\(.*\)"|PATH="/usr/local/hadoop:\1"|g' -i /etc/environment
  become: true


#OTROS
#ssh-keygen -t rsa
#ssh-copy-id hadoop@localhost

#Before: (1)
#/etc/hosts
#127.0.0.1 localhost
#10.138.0.2 hadoop-master

#slaves (2): AÃ±adir ips de workers into slaves file in master
#/usr/local/hadoop/etc/hadoop
#10.138.0.3
#10.138.0.4

#port: open 54310 port ingress

# Start namenode manual (3)
# cd /usr/local/hadoop/sbin
#./hadoop-daemon.sh --script hdfs start namenode
#jps
 
#TEST
# cd /usr/local/hadoop/bin
# ./hdfs dfs -ls /.
#./hdfs dfs -mkdir /edith
#./hdfs dfs -ls /.






